# Plan
Goal is to web scrape daily and save to DynamoDB table. Aim is to do in free tier of AWS as a learning project.

## Setup
* A venv has been created with the requried packages


## Tutorials
1. Follow this tutorial https://towardsdatascience.com/how-to-automate-financial-data-collection-with-python-using-tiingo-api-and-google-cloud-platform-b11d8c9afaa1
2. Not doing the above, now doing this one: https://docs.aws.amazon.com/AmazonCloudWatch/latest/events/RunLambdaSchedule.html
3. Not doing above, now doing this one: https://medium.com/@kagemusha_/scraping-on-a-schedule-with-aws-lambda-and-cloudwatch-caf65bc38848
3.1 Do this DynamoDB tutorial https://aws.amazon.com/getting-started/hands-on/create-nosql-table/
3.2 Then follow this one for how to do it from scraped data https://stackoverflow.com/questions/33535613/how-to-put-an-item-in-aws-dynamodb-using-aws-lambda-with-python

4. Could watch this video if get stuck: https://www.youtube.com/watch?v=Y0hqaTVwLw4